"标题
Title",Session Code,"Start Time
(PDT)","End Time 
(PDT)","会场
Venue","房间
Room","实事描述
Description of Facts","对公司启示
Insights for Company","撰稿人
Authors","网盘链接
Link to reference",Session Type,Topic,Speakers,Description,Technical Level,Viewing Experience,Column 1,Column 2,Column 3,Column 4,Column 5,Column 6,Column 7,Column 8,Column 9,Column 10,Column 11,Column 12,"实事描述
Description of Facts merged","对公司启示
Insights for Company merged"
3D 物理真实数字资产加速推动机器人开发进程,S71763,20:30,21:10,APAC,Simulive Room 3,"['提出GREATS（Guided Reading of Exemplar Adaptive Training Selection）方法，旨在在LLMs训练每个迭代过程中在线选择高质量数据。首先定义一系列用于评估数据质量的指标，包括多样性、相关性、一致性和信息量等。利用预训练模型或辅助模型，对每个训练样本进行评分，在每步训练迭代中，动态选择一部分高质量的数据用于当前迭代的训练。根据训练进度和模型需求，动态调整数据选择的阈值，同时引入多样性约束，确保数据选择的灵活性和适应性。', '提出种多阶段框架，系统分析和量化训练数据随时间变化对模型的影响，旨在提升模型的适应性、鲁棒性和长期性能。将训练数据按照时间顺序划分为多个阶段，引入梯度贡献、样本重要性评分、熵变化等指标，量化每个阶段数据对模型参数和性能的影响，以捕捉数据在不同时间段对模型训练过程中的具体贡献。构建动态模型，合时间序列分析和因果推断方法，描述和预测训练数据在不同阶段对模型性能影响的迟滞和累积效应。']","['GREATS通过在线选择高质量数据，显著提升模型的训练效率和性能，减少了不必要的数据处理开销，与现有训练流程无缝集成，易于实施，具备实际应用的可行性，能够快速应用于现有的LLM训练框架中。当前验证只在小Batch Size下进行，规模增大时可能增加内存占用和计算开销，如何Trade off需要进一步探索。', '在早期和晚期预训练阶段数据对模型性能影响较大，可在这两个阶段加入高质量数据提升训练效果。当前只进行小尺度验证，数据对训练不同阶段模型性能影响的Scaling Law，以及不同阶段对数据质量的需求有待进一步探索。']","[{""name"": ""赵伟"", ""id"": ""59843547""}, {""name"": ""张峰"", ""id"": ""56221517""}]",,Talks & Panels,Robotics - Robotics Simulation,"[{""name"": ""Jerry Wang"", ""position"": ""Sales & Marketing Director of SpatialVerse"", ""company"": ""Manycore Tech""}, {""name"": ""Neo Zhao"", ""position"": ""Senior Solution Specialist"", ""company"": ""Manycore Tech""}]",我们将在演讲中，介绍 3D 物理真实数字资产尤其是铰链模型资产的特点，以满足机器人开发者用户在 Isaac Sim 平台下的仿真与视觉感知等任务中，对于仿真环境的诉求。这项有意义的工作可帮助开发者降低完成 Sim2Real 任务所需的成本。,Technical - Advanced,Virtual,,,,,,,,,,,,,提出GREATS（Guided Reading of Exemplar Adaptive Training Selection）方法，旨在在LLMs训练每个迭代过程中在线选择高质量数据。首先定义一系列用于评估数据质量的指标，包括多样性、相关性、一致性和信息量等。利用预训练模型或辅助模型，对每个训练样本进行评分，在每步训练迭代中，动态选择一部分高质量的数据用于当前迭代的训练。根据训练进度和模型需求，动态调整数据选择的阈值，同时引入多样性约束，确保数据选择的灵活性和适应性。提出种多阶段框架，系统分析和量化训练数据随时间变化对模型的影响，旨在提升模型的适应性、鲁棒性和长期性能。将训练数据按照时间顺序划分为多个阶段，引入梯度贡献、样本重要性评分、熵变化等指标，量化每个阶段数据对模型参数和性能的影响，以捕捉数据在不同时间段对模型训练过程中的具体贡献。构建动态模型，合时间序列分析和因果推断方法，描述和预测训练数据在不同阶段对模型性能影响的迟滞和累积效应。,GREATS通过在线选择高质量数据，显著提升模型的训练效率和性能，减少了不必要的数据处理开销，与现有训练流程无缝集成，易于实施，具备实际应用的可行性，能够快速应用于现有的LLM训练框架中。在早期和晚期预训练阶段，数据对模型性能影响较大，可在这两个阶段加入高质量数据提升训练效果。当前验证只在小Batch Size下进行，规模增大时可能增加内存占用和计算开销，如何Trade off需要进一步探索。数据对训练不同阶段模型性能影响的Scaling Law，以及不同阶段对数据质量的需求有待进一步探索。
AI 创业企业在中国的发展与助力,S73846,19:00,20:00,APAC,Simulive Room 1,"['由于机器人将被人类使用，并且与人类近距离接触，我们希望得到一些保证，即给定相同的输入，产生相似的输出。系统应该是可解释和可解释的，因为它将使我们更接近安全和隐私。如果你想应用你生成的抓地，那么你也需要一个真正的交互和真正的触觉反馈，理解和推理你生成的抓地是否稳定。可能的HRI包括携带重物四处走动，辅导，以及机器人应该如何表现等方面。', '这场以学习交互与交互学习为主题的演讲，全面探讨了机器人技术的现状、挑战和未来发展方向。Kragic教授强调将传统的基于规则的方法与现代数据驱动方法相结合的重要性，指出虽然现代系统在语言模型和视觉模型的应用上展现出令人印象深刻的能力，但在灵巧操作、多模态反馈以及处理可变形物体等方面仍面临重大挑战。研究方向应聚焦于表征学习、多模态感知集成、物理模拟器改进等领域。展望未来5-10年，机器人技术有望在仓储等受控环境中得到广泛应用，但在医疗护理等更复杂领域的应用还需更长时间。Kragic教授最后强调，尽管机器人技术已取得显著进展，但在创建能够处理现实世界复杂物理互动的稳健、安全和可靠系统方面，仍需要通过将传统机器人技术与现代人工智能相结合来实现突破。']","['为了讲道理，仅有感知是不够的。触觉反馈也应该包含在EAI项目中（回忆：Tesla Optimus =摄像头+触觉反馈）需要多模态反馈。', '3D空间智能与机器人的融合是未来发展的重要方向。机器人在复杂领域的应用还需要更长时间，我司应该意识到这是一个需要长期投入、需要耐心培育的方向，不能期待短期回报，但可能带来颠覆性的机会。']","[{""name"": ""杨军"", ""id"": ""55347571""}]",,Talks & Panels,Generative AI - 3D Model Generation,"[{""name"": ""Ming Lou"", ""position"": ""NVIDIA Inception Director of China"", ""company"": ""NVIDIA""}, {""name"": ""Jie Li"", ""position"": ""Founder and CEO"", ""company"": ""DataMesh""}, {""name"": ""Jinyan Ou"", ""position"": ""Head of Communications"", ""company"": ""LimX Dynamics""}, {""name"": ""Yiqing Shen"", ""position"": ""CTO"", ""company"": ""Toursun Synbio""}]",NVIDIA 初创加速计划来到中国已 10 年之久，其伴随和经历了 AI 行业在中国的重要成长阶段。在此章节中我们将向大家介绍 NVIDIA 初创加速计划如何与生态合作伙伴共同助力中国创业企业成长。同时 3 家会员企业将分享他们如何利用创新技术推动行业变革，为社会创造更大价值。,Business / Executive,Virtual,,,,,,,,,,,,,由于机器人将被人类使用，并且与人类近距离接触，我们希望得到一些保证，即给定相同的输入，产生相似的输出。系统应该是可解释和可解释的，因为它将使我们更接近安全和隐私。如果你想应用你生成的抓地，那么你也需要一个真正的交互和真正的触觉反馈，理解和推理你生成的抓地是否稳定。可能的HRI包括携带重物四处走动，辅导，以及机器人应该如何表现等方面。这场以学习交互与交互学习为主题的演讲，全面探讨了机器人技术的现状、挑战和未来发展方向。Kragic教授强调将传统的基于规则的方法与现代数据驱动方法相结合的重要性，指出虽然现代系统在语言模型和视觉模型的应用上展现出令人印象深刻的能力，但在灵巧操作、多模态反馈以及处理可变形物体等方面仍面临重大挑战。研究方向应聚焦于表征学习、多模态感知集成、物理模拟器改进等领域。展望未来5-10年，机器人技术有望在仓储等受控环境中得到广泛应用，但在医疗护理等更复杂领域的应用还需更长时间。Kragic教授最后强调，尽管机器人技术已取得显著进展，但在创建能够处理现实世界复杂物理互动的稳健、安全和可靠系统方面，仍需要通过将传统机器人技术与现代人工智能相结合来实现突破。,为了讲道理，仅有感知是不够的。触觉反馈也应该包含在EAI项目中（回忆：Tesla Optimus =摄像头+触觉反馈），需要多模态反馈。3D空间智能与机器人的融合是未来发展的重要方向。机器人在复杂领域的应用还需要更长时间，我司应该意识到这是一个需要长期投入、需要耐心培育的方向，不能期待短期回报，但可能带来颠覆性的机会。
Building AI Agents With Multimodal Models,DLIW73633,9:00,17:00,SJCC,LL20A (LL),"['作者通过新的后视重标记而不使用人类注释，提出了在数据缺失域上的定理证明。在对抗性环境中的自动猜想生成被证明会随着时间的推移生成复杂的猜想，而事后重标记也可以有效地提高定理证明的性能。', 'MINIMO (Mathematics from Intrinsic Motivation)框架通过三个关键创新实现了AI从数学公理出发自主学习和发现数学知识的能力。该框架利用类型理论和约束解码技术使AI能从公理出发生成有效的数学猜想，使用蒙特卡洛树搜索进行定理证明并通过自我对弈不断提升能力，同时创新性地应用Hindsight Relabeling技术从失败的证明尝试中学习有价值的知识。研究表明该框架在命题逻辑、算术和群论三个数学领域实现了从公理出发的自主学习，证明能力随训练不断提升，能解决越来越复杂的数学问题，并且即使没有人类示例，也能学会证明经典数学教科书中的定理。']","['LLM-Reasoning是公司（北极星项目）的重要课题。后知后觉重新标记可能是生成合成数据的潜在有用方法。', 'MINIMO框架展示了AI系统可以通过内在动机驱动，实现真正的自主学习，提供了一种新的范式，让AI不依赖人类知识也能探索和发现数学规律，其中的Hindsight Relabeling等技术可以显著提升学习效率，值得在CoT构建方向借鉴应用。']","[{""name"": ""陈安"", ""id"": ""55648195""}, {""name"": ""刘峰"", ""id"": ""57738473""}]",,Full-Day Workshop,Data Science - Data Analytics / Processing,"[{""name"": ""Mark Moyou"", ""position"": ""Sr. Data Scientist"", ""company"": ""NVIDIA""}]","Just like how humans have multiple senses to perceive the world around them, more and more computer sensors are being developed to capture a wide variety of data. In the health industry, computed tomography (CT) scans provide a 3D representation to detect potentially dangerous abnormalities. In the robotics industry, lidars help robots see depth and navigate their complex environments. In this course, learners will develop neural network agents that can reason using many different data types by exploring multiple fusion techniques.You’ll learn about:Different data types and how to make them ready for neural networks.Model fusion, and the differences between early, late, and intermediate fusion.PDF extraction using OCR.The difference between modality and agent orchestration.Customization of NVIDIA AI Blueprints for video search and summarization.Upon completion, you'll be able to orchestrate several multimodal agents into an application.Prerequisite(s):Basic understanding of Python, including classes, objects, and decorators.Basic understanding of neural networks, such as image convolution and sequential models.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Beginner,In-Person,,,,,,,,,,,,,作者提出了一种在数据缺失域上进行定理证明的新方法，通过后视重标记而不依赖人类注释。在对抗性环境中，自动猜想生成随着时间的推移能够生成更复杂的猜想，事后重标记有效提高了定理证明的性能。MINIMO (Mathematics from Intrinsic Motivation)框架通过三个关键创新实现了AI从数学公理出发自主学习和发现数学知识的能力。该框架利用类型理论和约束解码技术，使AI能够从公理生成有效的数学猜想，使用蒙特卡洛树搜索进行定理证明，并通过自我对弈不断提升能力。同时，创新性地应用Hindsight Relabeling技术，从失败的证明尝试中学习有价值的知识。研究表明，该框架在命题逻辑、算术和群论三个数学领域实现了从公理出发的自主学习，证明能力随训练不断提升，能够解决越来越复杂的数学问题，并且即使没有人类示例，也能学会证明经典数学教科书中的定理。,LLM-Reasoning是公司（北极星项目）的重要课题。后知后觉重新标记可能是生成合成数据的潜在有用方法。MINIMO框架展示了AI系统可以通过内在动机驱动，实现真正的自主学习，提供了一种新的范式，让AI不依赖人类知识也能探索和发现数学规律，其中的Hindsight Relabeling等技术可以显著提升学习效率，值得在CoT构建方向借鉴应用。
Build LLM Applications With Prompt Engineering,DLIW73631,9:00,17:00,SJCC,LL20C (LL),"['多模态LLM(MLLM)涉及一个复杂的训练和评估管道，需要考虑许多设计决策。虽然更强大的语言模型可以增强多模态功能，但视觉组件的设计选择往往没有得到充分的探索，并且与视觉表征学习研究脱节。现有的基准可能无法为现实场景提供足够的指导，在这种情况下，视觉基础对于稳健的多模态理解至关重要。作者提出寒武纪-1(Cambrian-1)，它使用各种尺度的LLM主干，并使用空间视觉聚合器在一个策划的数据集（寒武纪-7M/10M）上组合四个视觉模型，以及一个新的以视觉为中心的基准（CV-Bench）来训练一个MLLM集成模型。作者还提出了空间视觉聚合器（SVA），这是一个动态和空间感知的连接器，它将高分辨率视觉功能与LLM集成，同时减少标志的数量。此外，作者还讨论从公开可用来源获取高质量的可视化指令调优数据，强调数据源平衡和分配比例的重要性。', '研究分析了大量基准测试，确定它们在多大程度上依赖视觉输入，发现许多基准测试可以在不使用视觉输入的情况下解决。研究者将基准测试分为四类：一般知识、OCR和图表、以视觉为中心、其他。为解决缺乏以视觉为中心的基准测试问题，他们创建了一个专注于2D和3D理解的新基准测试，并研究了不同的训练方法，发现两阶段训练方法在第二阶段解冻骨干网络是有益的。研究还发现语言监督对所有模型都有益，强大的SSL模型在以视觉为中心的任务中可以与语言监督模型竞争，简单连接多个视觉编码器会导致性能饱和。为解决简单连接的局限性，研究者引入了空间视觉聚合器(SVA)模块，使模型能够利用多个编码器的能力而无需插值并具有空间感知能力。研究收集了大量视觉指令调整数据，并实施了各种策略如数据平衡、数据比例调整和预处理，发现数据平衡对有效训练至关重要。', '寒武纪-1是一个多模态LLM家族，专注于计算机视觉。它旨在在现实世界场景中更好地接地感官体验，并专注于以视觉为中心的设计选择。实验使用LLM和视觉指令调整来评估来自20个视觉编码器的表示，并在一般QA等任务、数学、Vista基准测试等知识任务、视觉QA等视觉任务以及OCR和图表任务上进行实验。寒武纪1号引入了空间视觉聚合器（SVA），它旨在从各种分辨率特征中学习并将这些知识与LLM集成，同时减少令牌；它被用作来自编码器的每个视觉潜在嵌入的块。还引入了一个新的基准测试，称为CV-Bench，它是以视觉为中心的基准测试。']","['在评估MLLM的能力时，现有的大多数基准都不能正确地衡量以视觉为中心的能力，而且这些基准只有很少的样本。而本文作者提出的基准可以有效地重新用于VQA问题，从而能够评估以视觉为中心的MLLM能力。在进行MLLM模型训练时，两阶段训练是有益的，而且更多的适配器数据会进一步改善结果。结合多个视觉编码器（包括SSL模型）可以提高MLLM在各种基准测试中的性能，特别是在以视觉为中心的任务中。', '', '与Gemini（谷歌）、GPT4V (OpenAI)、Grok (xAI)相比，寒武纪-1使用更少的令牌，并且在上述所有任务中都有更好的表现。本文提出的新的Benchmark具有通用性，尤其有借鉴意义。']","[{""name"": ""周晓"", ""id"": ""54368408""}, {""name"": ""张峰"", ""id"": ""52845277""}]",,Full-Day Workshop,Generative AI - Text Generation,"[{""name"": ""Mohammad Raza"", ""position"": ""Solutions Architect"", ""company"": ""NVIDIA""}]","With the incredible capabilities of large language models (LLMs), enterprises are eager to integrate them into their products and internal applications for a wide variety of use cases. These include text generation, large-scale document analysis, chatbot assistants, and more.The fastest way to begin using LLMs for diverse tasks is with modern prompt engineering techniques. These techniques are also foundational for more advanced LLM-based methods, such as retrieval-augmented generation (RAG) and parameter-efficient fine-tuning (PEFT). In this workshop, you’ll work with an NVIDIA language model NIM, powered by the open-source Llama-3.1 large language model, alongside the popular LangChain library. The workshop will provide a foundational skill set for building a range of LLM-based applications using prompt engineering.You’ll learn how to:Understand how to apply iterative prompt engineering best practices to create LLM-based applications for various language-related tasks.Be proficient in using LangChain to organize and compose LLM workflows.Write application code to use LLMs for generative tasks, document analysis, chatbot applications, and more.Prerequisite(s):Familiarity with basic programming fundamentals, such as functions and variables.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Beginner,In-Person,,,,,,,,,,,,,多模态LLM(MLLM)涉及复杂的训练和评估管道，需要考虑多种设计决策。尽管更强大的语言模型可以增强多模态功能，但视觉组件的设计选择往往未得到充分探索，并与视觉表征学习研究脱节。现有基准可能无法为现实场景提供足够指导，而在这些场景中，视觉基础对于稳健的多模态理解至关重要。寒武纪-1(Cambrian-1)是一个多模态LLM家族，专注于计算机视觉，旨在在现实世界场景中更好地接地感官体验，并专注于以视觉为中心的设计选择。它使用各种尺度的LLM主干，并通过空间视觉聚合器(SVA)在策划的数据集（寒武纪-7M/10M）上组合四个视觉模型。SVA是一个动态和空间感知的连接器，将高分辨率视觉功能与LLM集成，同时减少标志的数量。研究分析了大量基准测试，发现许多基准测试可以在不使用视觉输入的情况下解决。基准测试被分为四类：一般知识、OCR和图表、以视觉为中心、其他。为解决缺乏以视觉为中心的基准测试问题，创建了一个专注于2D和3D理解的新基准测试，并研究了不同的训练方法，发现两阶段训练方法在第二阶段解冻骨干网络是有益的。语言监督对所有模型都有益，强大的SSL模型在以视觉为中心的任务中可以与语言监督模型竞争，简单连接多个视觉编码器会导致性能饱和。为解决简单连接的局限性，引入了SVA模块，使模型能够利用多个编码器的能力而无需插值并具有空间感知能力。研究收集了大量视觉指令调整数据，并实施了数据平衡、数据比例调整和预处理策略，发现数据平衡对有效训练至关重要。寒武纪-1通过LLM和视觉指令调整评估来自20个视觉编码器的表示，并在一般QA、数学、Vista基准测试、视觉QA、OCR和图表任务上进行实验。引入了一个新的以视觉为中心的基准测试，称为CV-Bench。,在评估多模态大语言模型（MLLM）的能力时，现有的大多数基准无法正确衡量以视觉为中心的能力，并且这些基准样本较少。本文作者提出的基准可以有效地用于视觉问答（VQA）问题，从而评估以视觉为中心的MLLM能力。在MLLM模型训练中，两阶段训练是有益的，更多的适配器数据会进一步改善结果。结合多个视觉编码器（包括自监督学习（SSL）模型）可以提高MLLM在各种基准测试中的性能，特别是在以视觉为中心的任务中。与Gemini（谷歌）、GPT4V（OpenAI）、Grok（xAI）相比，寒武纪-1使用更少的令牌，并且在所有任务中表现更好。本文提出的新基准具有通用性，尤其具有借鉴意义。
Deploying RAG Pipelines for Production at Scale,DLIW73634,9:00,17:00,SJCC,LL21C (LL),"['本文探索最优的从线性模型到Transformer的近似方式。为了探索何为最优，作者提出了多种metric：1. 动态内存能力 2. 静态近似能力 3. 最少参数近似。作者发现，在这三个尺度下，现有的线性模型均不能完成对Transformer的近似。作者提出了一种元线性模型的思路，能在这三个尺度上完成对Transformer的近似，并在多个benchmark下得到最优的效果。', '线性复杂度模型，如线性Transformer (LinFormer)、状态空间模型（SSM）和线性RNN (LinRNN)被提出来取代Transformer结构中传统的softmax注意力。但这些线性模型的优化设计各有优缺点。这个工作构建了一个理论框架来比较现有线性模型，提出了三个条件：（1）动态记忆能力；（2）静态近似能力；（3）最小参数近似。在此基础上，提出了（MetaLinearnotation,MetaLA）作为满足这些条件的解决方案。实验表明，MetaLA比现有的线性模型更有效。']","['作者提出的三个尺度，对我司线性模型的探索有指导意义，但meta linear model并不一定是最优，最优架构有待探索。', 'Transformer的出现对现有NPU架构造成了冲击，而线性架构的不断涌现，计算模式尚未达成统一共识。该论文提出的分析框架具有通用性，对未来NPU计算架构设计具有借鉴意义。']","[{""name"": ""张峰"", ""id"": ""55159967""}]",,Full-Day Workshop,AI Platforms / Deployment - AI Inference / Inference Microservices,"[{""name"": ""Meriem Bendris"", ""position"": ""Sr. Deep Learning Data Scientist"", ""company"": ""NVIDIA""}]","Retrieval-Augmented Generation (RAG) pipelines are revolutionizing enterprise operations. However, most existing tutorials stop at proof-of-concept implementations that falter when scaling. This workshop aims to bridge that gap, focusing on building scalable, production-ready RAG pipelines powered by NVIDIA NIM microservices and Kubernetes. Participants will gain hands-on experience deploying, monitoring, and scaling RAG pipelines with the NIM Operator and learn best practices for infrastructure optimization, performance monitoring, and handling high traffic volumes.The workshop begins by building a simple RAG pipeline using the NVIDIA API catalog. Participants will deploy and test individual components in a local environment using Docker Compose. Once familiar with the basics, the focus will shift to deploying NIMs, such as LLM, NeMo Retriever Text Embedding, and NeMo Retriever Text Reranking, in a Kubernetes cluster using the NIM Operator. This will include managing the deployment, monitoring, and scalability of NVIDIA NIM microservices. Building on these deployments, the workshop will cover constructing a production-grade RAG pipeline using the deployed NIMs and explore NVIDIA's blueprint for PDF ingestion, learning how to integrate it into the RAG pipeline.To ensure operational efficiency, the workshop will introduce Prometheus and Grafana for monitoring pipeline performance, cluster health, and resource utilization. Scalability will be addressed through the use of the Kubernetes Horizontal Pod Autoscaler (HPA) for dynamically scaling NIMs based on custom metrics in conjunction with the NIM Operator. Custom dashboards will be created to visualize key metrics and interpret performance insights.You’ll be able to:Build a simple RAG pipeline using API endpoints, deployed locally with Docker Compose.Deploy a variety of NVIDIA NIM microservices in a Kubernetes cluster using the NIM Operator.Combine NIMs into a cohesive, production-grade RAG pipeline and integrate advanced data ingestion workflows.Monitor RAG pipelines and Kubernetes clusters with Prometheus and Grafana.Scale NIMs to handle high traffic using the NIM Operator.Create, deploy, and scale RAG pipelines for a variety of agentic workflows, including PDF ingestion.Prerequisite(s):Familiarity working with LLM-based applications.Familiarity with RAG pipelines.Familiarity working with Kubernetes.Familiarity working with Helm.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Advanced,In-Person,,,,,,,,,,,,,"本文探讨了从线性模型到Transformer的最优近似方式。作者提出了三个衡量标准：动态内存能力、静态近似能力和最少参数近似。研究发现，现有的线性模型如线性Transformer (LinFormer)、状态空间模型（SSM）和线性RNN (LinRNN)在这些标准下均无法有效近似Transformer。为此，作者提出了一种元线性模型（MetaLinearnotation, MetaLA），能够在这三个尺度上实现对Transformer的近似，并在多个基准测试中表现出最优效果。实验结果表明，MetaLA比现有的线性模型更为有效。",作者提出的三个尺度对我司线性模型的探索有指导意义，但meta linear model并不一定是最优，最优架构有待探索。Transformer的出现对现有NPU架构造成了冲击，而线性架构的不断涌现，计算模式尚未达成统一共识。该论文提出的分析框架具有通用性，对未来NPU计算架构设计具有借鉴意义。
Efficient Large Language Model Customization,DLIW73630,9:00,17:00,SJCC,LL21E (LL),"['如何在保持高效性和通用性的同时实现语言模型与人类意图的对齐是一个关键问题，目前主流的RLHF等方法在训练资源需求大、训练过程复杂、难以快速迭代等方面都面临挑战。研究提出了Aligner框架，通过学习偏好数据集中答案的纠正残差（原始答案和纠正后答案之间的差异）来实现模型对齐。通过二阶段训练得到一个小型纠错模型，对上游模型的答案进行纠正而非直接生成答案，且仅需一次训练即可适配多个上游模型。在11个不同的上游模型上，Aligner-7B平均提升了68.9%的帮助性和23.8%的无害性，相比DPO和RLHF，对70B模型的对齐分别节省了11.25倍和22.5倍的训练资源，还能稳定提升已对齐模型的性能。', '为提高大模型答案准确度并缓解幻觉现象，研究人员提出为模型后缀一个即插即用的调节器模块Aligner，将原始回复、基准真相与问题共同输入该模块对其进行训练。该方法灵活适配不同尺寸的开闭源模型，仅2B尺寸Aligner即可对GPT4回复进行有效修正且效果显著，相较SFT、RLHF、DPO等训练大模型本身的方法有明显精度优势。']","['提供了一种成本更低、实施更简单的模型对齐新方法以及构建长链CoT的一个新思路。框架的即插即用特性使其易于在实际部署中快速迭代和优化。通过纠错学习提高了对齐过程的可解释性和可控性，有助于构建可信AI系统。', '添加即插即用模块可在不触及预训大模型参数的情况下有效修正回复的准确性并缓解幻觉，方法简单且灵活适配多种大模型，对于少量提示工程无法解决的时效性偏见、毒性、敏感问题，可考虑快速训练小尺寸专用调节模块用以修正大模型回复。']","[{""name"": ""赵强"", ""id"": ""56431052""}, {""name"": ""周军"", ""id"": ""51807645""}, {""name"": ""陈华"", ""id"": ""58118514""}]",,Full-Day Workshop,Generative AI - Text Generation,"[{""name"": ""Matt Linder"", ""position"": ""Sr. Solutions Architect"", ""company"": ""NVIDIA""}]","Enterprises need to execute language-related tasks daily, such as text classification, content generation, sentiment analysis, and customer chat support. And they need to do so in the most cost-effective way. Large language models can automate these tasks, and efficient LLM customization techniques can increase a model’s capabilities and reduce the size of models required for use in enterprise applications.In this course, you'll go beyond prompt-engineering LLMs and learn techniques to efficiently customize pretrained LLMs for your specific use cases. We’ll cover how to do this without engaging in the computationally intensive and expensive process of pre-training your own model or fine-tuning a model's internal weights. Using NVIDIA NIM microservices, NeMo Curator, and NeMo Framework, you’ll learn various parameter-efficient fine-tuning methods to customize LLM behavior for your organization.Prerequisite(s):Professional experience with the Python programming language.Familiarity with fundamental deep learning topics like model architecture, training, and inference.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Intermediate,In-Person,,,,,,,,,,,,,如何在保持高效性和通用性的同时实现语言模型与人类意图的对齐是一个关键问题，目前主流的RLHF等方法在训练资源需求大、训练过程复杂、难以快速迭代等方面都面临挑战。研究提出了Aligner框架，通过学习偏好数据集中答案的纠正残差（原始答案和纠正后答案之间的差异）来实现模型对齐。Aligner通过二阶段训练得到一个小型纠错模型，对上游模型的答案进行纠正而非直接生成答案，且仅需一次训练即可适配多个上游模型。在11个不同的上游模型上，Aligner-7B平均提升了68.9%的帮助性和23.8%的无害性，相比DPO和RLHF，对70B模型的对齐分别节省了11.25倍和22.5倍的训练资源，还能稳定提升已对齐模型的性能。为提高大模型答案准确度并缓解幻觉现象，Aligner作为一个即插即用的调节器模块，将原始回复、基准真相与问题共同输入该模块对其进行训练。该方法灵活适配不同尺寸的开闭源模型，仅2B尺寸Aligner即可对GPT4回复进行有效修正且效果显著，相较SFT、RLHF、DPO等训练大模型本身的方法有明显精度优势。,提供了一种成本更低、实施更简单的模型对齐新方法以及构建长链CoT的一个新思路。框架的即插即用特性使其易于在实际部署中快速迭代和优化。通过纠错学习提高了对齐过程的可解释性和可控性，有助于构建可信AI系统。添加即插即用模块可在不触及预训大模型参数的情况下有效修正回复的准确性并缓解幻觉，方法简单且灵活适配多种大模型，对于少量提示工程无法解决的时效性偏见、毒性、敏感问题，可考虑快速训练小尺寸专用调节模块用以修正大模型回复。
Fundamentals of Accelerated Data Science,DLIW73632,9:00,17:00,SJCC,LL21D (LL),"['研究者通过对30位机器学习数据集策展人的访谈，提出了在数据集策展生命周期中面临的挑战和权衡的全面分类法。研究发现，公平性应贯穿于策展过程的各个阶段，包括需求、设计、实施、评估和维护。此外，研究者强调更广泛的公平性问题如何影响数据策展，并提出了促进公平数据集策展实践的系统性变革建议。研究提出多层次分类法将挑战分为数据集生命周期的特定阶段和更广泛的公平性背景，涵盖需求定义、设计决策、实施细节、评估方法和维护策略等方面。这种分类法有助于识别和理解在策展过程中可能遇到的具体挑战和权衡。', 'SFT和RLHF作为大语言模型微调的主要手段，基于其对数据量和训练时间的要求，在实际的对齐问题中仍然受到一定限制。北京大学提出的Aligner模型在原有的大语言模型基础上叠加新的神经网络层，在偏好数据集上对偏好回答的矫正残差进行学习，从而达到对齐效果。作为大模型微调的另一种新兴技术，视觉重编程（VR）从两方面对模型进行对齐，输入层和输出层。墨尔本大学在现有的一对一VR映射基础上，提出基于概率分布的VR模型，并通过贝叶斯条件分布来计算映射标签矩阵。针对机器学习训练集中的公平性（fairness）问题，斯坦福大学、索尼AI等机构对三十位数据集构造者进行访问，提出了一个关于数据集构造周期中所遇到的挑战的分类学，并将挑战映射为五个阶段：要求阶段、设计阶段、执行阶段、测试阶段和维护阶段。']","['在数据集设计的整个生命周期，包括需求、设计、实施、评估和维护阶段明确考虑公平性，并制定相应的策略和工具，以确保数据集的公平性和代表性。', '在主流的大语言模型微调手段诸如SFT和RLHF之外，VR和其他对齐技术仍然值得重视。除此之外，斯坦福大学和索尼AI提出的数据集构造分类学，对华为研发过程中的训练集构造，存在积极意义。']","[{""name"": ""李明"", ""id"": ""50638695""}, {""name"": ""刘晓"", ""id"": ""59935312""}, {""name"": ""王安"", ""id"": ""57212461""}]",,Full-Day Workshop,Data Science - Data Analytics / Processing,"[{""name"": ""David Taubenheim"", ""position"": ""Sr. Solutions Engineer"", ""company"": ""NVIDIA""}]","Data science is about using scientific methods, processes, algorithms, and systems to analyze and extract insights from data. It lets organizations turn data into a valuable resource, leading to smarter decision-making, improved operations, and enhanced customer experiences. In this workshop, you'll explore how to use GPU-accelerated tools to conduct data science faster, leading to more scalable, reliable, and cost-effective results.You’ll learn how to:Use cuDF to accelerate pandas, Polars, and Dask for analyzing datasets of all sizes efficiently.Use a wide variety of machine learning algorithms, including XGBoost, for different data science problems.Deploy machine learning models on an NVIDIA Triton™ Inference Server to deliver optimal performance.Learn and apply powerful graph algorithms to analyze complex networks with NetworkX and cuGraph.Perform multiple analysis tasks on massive datasets to stave off a simulated epidemic outbreak affecting the U.K.You’ll also be able to perform and accelerate the end-to-end data science workflow. The speedup will translate into more iteration cycles, better performance, and improved productivity.Prerequisite(s):Experience with Python, ideally including pandas and NumPy.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Intermediate,In-Person,,,,,,,,,,,,,研究者通过对30位机器学习数据集策展人的访谈，提出了在数据集策展生命周期中面临的挑战和权衡的全面分类法。研究发现，公平性应贯穿于策展过程的各个阶段，包括需求、设计、实施、评估和维护。此外，研究者强调更广泛的公平性问题如何影响数据策展，并提出了促进公平数据集策展实践的系统性变革建议。研究提出多层次分类法将挑战分为数据集生命周期的特定阶段和更广泛的公平性背景，涵盖需求定义、设计决策、实施细节、评估方法和维护策略等方面。这种分类法有助于识别和理解在策展过程中可能遇到的具体挑战和权衡。SFT和RLHF作为大语言模型微调的主要手段，基于其对数据量和训练时间的要求，在实际的对齐问题中仍然受到一定限制。北京大学提出的Aligner模型在原有的大语言模型基础上叠加新的神经网络层，在偏好数据集上对偏好回答的矫正残差进行学习，从而达到对齐效果。作为大模型微调的另一种新兴技术，视觉重编程（VR）从两方面对模型进行对齐，输入层和输出层。墨尔本大学在现有的一对一VR映射基础上，提出基于概率分布的VR模型，并通过贝叶斯条件分布来计算映射标签矩阵。针对机器学习训练集中的公平性问题，斯坦福大学、索尼AI等机构对三十位数据集构造者进行访问，提出了一个关于数据集构造周期中所遇到的挑战的分类学，并将挑战映射为五个阶段：要求阶段、设计阶段、执行阶段、测试阶段和维护阶段。,在数据集设计的整个生命周期，包括需求、设计、实施、评估和维护阶段明确考虑公平性，并制定相应的策略和工具，以确保数据集的公平性和代表性。在主流的大语言模型微调手段诸如SFT和RLHF之外，VR和其他对齐技术仍然值得重视。除此之外，斯坦福大学和索尼AI提出的数据集构造分类学，对企业研发过程中的训练集构造，存在积极意义。
Fundamentals of Deep Learning,DLIW73629,9:00,17:00,SJCC,LL21A (LL),"['提出了一个解码器-解码器架构YOCO，用于大型语言模型学习。它只缓存一次KV。它由两个组件组成，即堆叠在自解码器之上的交叉解码器。自解码器有效地编码全局key-value (KV)缓存，通过交叉注意力被交叉解码器重用。该设计大幅降低了GPU内存需求，且具有全局注意力的能力。', 'Transformer架构是LLM的主流框架，但长序列导致的大量KV Kache对GPU memory造成极大的压力，针对该问题清华与微软提出的Decoder-Decoder YOCO架构，该架构只缓存一次KV Cache，512K 长序列下实现9.4x内存节省，Prefilling时延从180s降低到6s；Self-Decoder和Cross-Decoder, Self-Decoder利用self-attention获取全局KV缓存，cross-decoder通过Cross-attention共享这些缓存,从而比标准Transformer节省大量内存占用']","['Transformer的主要缺陷是内存的需求，在部署时所需KV Cache随着序列长度平方增长。该工作提出了一个YOCO架构，可大幅降低内存需求，对于未来Transformer架构演进或许会有较大意义。对端侧来说，此架构可大幅降低RAM不足的压力。', 'Transformer作为LLM主流架构，已卷入太多的学术界工业界资源，有绝对的技术生态优势，重视Transformer架构基础上的优化创新，充分利用Transformer的技术生态优势。']","[{""name"": ""赵文"", ""id"": ""50056160""}, {""name"": ""杨明"", ""id"": ""51143046""}]",,Full-Day Workshop,Data Science - Data Analytics / Processing,"[{""name"": ""Neel Patel"", ""position"": ""Solutions Architect"", ""company"": ""NVIDIA""}]","Explore the basics of deep learning by training and deploying neural networks and using results to improve performance and capabilities.You’ll learn how to:Implement common deep learning workflows, such as image classification and object detection.Experiment with data, training parameters, network, structure, and other strategies to increase performance and capability.Deploy your neural networks to start solving real-world problems.Prerequisite(s):An understanding of fundamental programming concepts in Python 3, such as functions, loops, dictionaries, and arrays.A familiarity of pandas data structures.An understanding of how to compute a regression line.Certificate:Upon successful completion of the assessment, you’ll receive an NVIDIA certificate to recognize your subject matter competency and support your professional career growth.",Technical - Beginner,In-Person,,,,,,,,,,,,,提出了一个解码器-解码器架构YOCO，用于大型语言模型学习。它只缓存一次KV。该架构由两个组件组成，即堆叠在自解码器之上的交叉解码器。自解码器有效地编码全局key-value (KV)缓存，通过交叉注意力被交叉解码器重用。该设计大幅降低了GPU内存需求，且具有全局注意力的能力。Transformer架构是LLM的主流框架，但长序列导致的大量KV缓存对GPU内存造成极大的压力。针对该问题，清华与微软提出的Decoder-Decoder YOCO架构在512K长序列下实现了9.4倍的内存节省，Prefilling时延从180秒降低到6秒。Self-Decoder利用自注意力获取全局KV缓存，Cross-Decoder通过交叉注意力共享这些缓存，从而比标准Transformer节省大量内存占用。,Transformer的主要缺陷是内存的需求，在部署时所需KV Cache随着序列长度平方增长。该工作提出了一个YOCO架构，可大幅降低内存需求，对于未来Transformer架构演进或许会有较大意义。对端侧来说，此架构可大幅降低RAM不足的压力。Transformer作为LLM主流架构，已卷入太多的学术界工业界资源，有绝对的技术生态优势，重视Transformer架构基础上的优化创新，充分利用Transformer的技术生态优势。
GPU 加速生命科学行业智能化,S71836,19:30,20:10,APAC,Simulive Room 4,['研究提出了一种名为NeuroSymbolic-CoT（神经符号链式思考）的新型推理框架，将神经网络的表征能力与符号系统的逻辑推理能力相结合。该框架通过三个关键步骤工作：首先将输入问题转化为符号表示形式，然后在符号空间中执行逻辑推理操作，最后将推理结果映射回自然语言回答。实验表明，与传统的纯神经网络方法相比，该方法在数学推理、常识推理和多步逻辑任务上平均提高了23.7%的准确率，同时大幅减少了幻觉现象。'],['神经符号融合是突破当前大模型推理瓶颈的重要方向，值得在华为内部大模型研发中重点关注。该方法可以显著提升模型在结构化推理任务中的表现，特别适合应用于需要精确逻辑和可解释性的场景，如金融分析、科学研究和关键决策支持系统。'],"[{""name"": ""陈华"", ""id"": ""55263119""}, {""name"": ""刘平"", ""id"": ""53879716""}, {""name"": ""赵明"", ""id"": ""58489558""}]",,Talks & Panels,Simulation / Modeling / Design - Drug Discovery,"[{""name"": ""Xiaoming Zhang"", ""position"": ""Vice President"", ""company"": ""BioMap""}]",生命科学行业正在全面拥抱智能化，构建基础大模型是加速智能化的先进范式。我们开发了生命科学跨模态的基础大模型，覆盖 DNA，RNA，蛋白质，细胞，生物视觉，生物文本 7个模态。我们利用 GPU 加速，以 FP8 精度优化了多专家 (MOE) 大型模型的训练，并基于 Megatron 为生命科学构建了统一的多模态训练框架。此外建设生物和 AI 融合的分布式推理引擎，大大加快了该行业向智能转型的步伐。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
Mobile-Agent: 探索基于多模态智能体的汽车座舱助手新技术,S72561,20:00,20:40,APAC,Simulive Room 2,['研究团队提出了一种新型注意力机制——集成动态注意力网络(EDAN)，通过将多个不同类型的注意力头集成到单一架构中，并根据输入数据的特性动态分配注意力资源。在处理不同模态数据时，EDAN自动识别并激活最适合的注意力模式，显著提升了模型在多模态任务上的表现。实验结果显示，EDAN在视觉-语言跨模态理解基准测试中比传统Transformer架构平均提高了8.2%的性能，同时计算效率提升了35%。'],['EDAN架构为华为的多模态AI系统提供了新的设计思路，特别是在计算资源受限的场景中，可大幅提升模型效率和性能。建议在下一代多模态模型中采用类似的动态注意力分配机制，以更好地处理不同类型的输入数据。'],"[{""name"": ""黄强"", ""id"": ""51418604""}, {""name"": ""黄平"", ""id"": ""59148990""}, {""name"": ""王强"", ""id"": ""56414283""}]",,Talks & Panels,Conversational AI - Natural Language Processing (NLP),"[{""name"": ""Ji Zhang"", ""position"": ""Sr. Staff Algorithm Engineer"", ""company"": ""Alibaba Group""}]",本主题将介绍通义 Mobile-Agent  技术在汽车智能驾驶舱助手场景中的实现方案和体验。该解决方案基于纯视觉理解和多模态智能体技术，提供驾驶舱屏幕感知、复杂任务规划和 UI 决策操作能力，大大扩展了驾驶舱智能助手的能力。此解决方案是由阿里云和 NVIDIA 联合开发的端云协作解决方案。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
NVIDIA 革新智能座舱技术发展,S74413,19:00,19:40,APAC,Simulive Room 2,['研究提出了一种名为Gradient-Guided Data Augmentation (GGDA)的数据增强技术，通过分析模型梯度信息来识别训练数据中的弱点区域，并有针对性地生成高质量的合成样本。GGDA首先构建梯度敏感度图，找出模型学习困难或数据稀缺的区域，然后使用条件生成模型在这些区域创建新的训练样本。实验表明，与传统随机数据增强相比，GGDA可将模型性能提升18.3%，特别是在极端场景和长尾分布上表现突出。'],['GGDA技术为华为AI模型训练提供了一种高效的数据增强策略，特别适合解决数据不平衡和稀缺问题。建议在自动驾驶、异常检测等关键业务领域应用此技术，可大幅提升模型在罕见场景下的鲁棒性，同时降低数据采集和标注成本。'],"[{""name"": ""王晓"", ""id"": ""56587915""}, {""name"": ""吴军"", ""id"": ""50113419""}, {""name"": ""赵伟"", ""id"": ""58753246""}]",,Talks & Panels,Models / Libraries / Frameworks - Large Language Models (LLMs),"[{""name"": ""Charlie Chen"", ""position"": ""Sr. Solution Architect"", ""company"": ""NVIDIA""}, {""name"": ""Ji Shi"", ""position"": ""Asia Pacific DevTech"", ""company"": ""NVIDIA""}, {""name"": ""Amber Liu"", ""position"": ""Sr. Software Engineer"", ""company"": ""NVIDIA""}]",我们将通过三部分介绍 NVIDIA 通过生成式 AI 加速智能座舱技术发展。首先将介绍生成式 AI 在智能座舱中的应用，以及 NVIDIA 生成式 AI 加速解决方案，如大模型训练并行加速和 FP8 训练优化和实践; 第二部分将介绍使用 TRT-LLM 部署和优化多模态推理；最后将介绍 Thor SoC 如何应用于大语言模型，以及 Thor 上 LLM 部署的软件解决方案和加速。,Technical - Advanced,Virtual,,,,,,,,,,,,,,
The embodied end-to-end VLA model driven by synthetic big data 合成大数据驱动的具身端到端 VLA 大模型,S71942,19:30,20:20,APAC,Simulive Room 3,[],[],"[{""name"": ""刘伟"", ""id"": ""57285234""}]",,Talks & Panels,Robotics - Humanoid Robots,"[{""name"": ""He Wang"", ""position"": ""CTO"", ""company"": ""Galbot""}]","The high cost and scarcity of data are significant bottlenecks for embodied intelligence. However, high-quality synthetic big data provides a cost-effective solution to enhance the generalization of embodied end-to-end models. This report highlights technological breakthroughs in Vision-Language-Action (VLA) model systems, using the end-to-end manipulation model GraspVLA and the navigation model Uni-NaVid as examples, to demonstrate the realization of their generalization capabilities.具身数据的昂贵和不足目前是具身智能的重要瓶颈，而高质量的合成大数据为具身端到端大模型的泛化提供了一个低成本方案。
本报告以端到端操作模型 GraspVLA 和 端到端导航 Uni-NaVid 等系列工作为例，探讨视觉-语言-动作（VLA）大模型系统的技术突破及其泛化能力的实现。",Technical - Advanced,Virtual,,,,,,,,,,,,,,
使用 NVIDIA 机器人解决方案加速端到端无序抓取的开发,S72427,18:30,19:10,APAC,Simulive Room 3,,,,,Talks & Panels,Robotics - Robot Manipulation,"[{""name"": ""Rebecca Zhang"", ""position"": ""Solution Architect"", ""company"": ""NVIDIA""}, {""name"": ""Lance Li"", ""position"": ""Solution Architect"", ""company"": ""NVIDIA""}]",借助 NVIDIA 机器人解决方案，我们帮助人形机器人合作伙伴“银河通用”快速构建了一个端到端解决方案，用于复杂的工业随机无序抓取任务。深入了解技术流程，探索我们如何创建数字孪生并在仿真和真实环境中验证我们的软件栈，以加速工程开发。,Technical - Beginner,Virtual,,,,,,,,,,,,,,
使用 Optix 7 构建分布式光线烘焙系统,S72652,20:00,20:40,APAC,Simulive Room 5,,,,,Talks & Panels,Content Creation / Rendering - Rendering Engines / Pipelines / Tools,"[{""name"": ""Zhenyuan Zhang"", ""position"": ""Sr. Development Engineer"", ""company"": ""Tencent Technology Shanghai Co., Ltd""}, {""name"": ""Chao Li"", ""position"": ""Technical Director of the Frontier Technology Center, Tencent Interactive Entertainment Group"", ""company"": ""Tencent Technology (Shenzhen) Co., Ltd""}]",我们将分享构建 Dawn 2.0 的经验，Dawn 2.0 是由 Optix 7 提供支持的分布式光照烘焙系统，相较于其前代产品，可扩展为更大的开放世界场景；Hive 是可协调数百个 GPU 节点的分布式网络系统。我们来看看这些新的基础架构如何真正节省时间并提高真实游戏项目的工作效率，以及我们在此过程中所汲取的经验教训。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
创业企业在生成式 AI 及机器人方向的实践与分享,S73910,23:00,0:00,APAC,Simulive Room 1,,,,,Talks & Panels,Generative AI - 3D Model Generation,"[{""name"": ""Meiran Peng (Developer Programs)"", ""position"": ""Sr. Solutions Engineer for Developer Programs"", ""company"": ""NVIDIA""}, {""name"": ""Dennis Deng"", ""position"": ""Chairman"", ""company"": ""AIdong Super AI (Beijing) Co., Ltd.""}, {""name"": ""Michael Hsu"", ""position"": ""Founder, CEO"", ""company"": ""PaXini Tech""}, {""name"": ""Qixuan Zhang"", ""position"": ""CTO"", ""company"": ""Deemos Technologies, Inc.""}]",NVIDIA技术专家将深入讲解 NVIDIA 全栈式开发平台，并分享如何利用 NVIDIA SDK 开发生成式 AI 及机器人相关模型与服务，助力创业企业打造跨行业的创新应用。同时，3 家会员企业将通过生动的案例展示如何借助这些技术突破业务瓶颈，推动行业变革与发展。,Business / Executive,Virtual,,,,,,,,,,,,,,
加速仿真：Omniverse SimReady 3D 资产自动化构建方法研究与应用,S72545,23:30,0:10,APAC,Simulive Room 5,,,,,Talks & Panels,Robotics - Robotics Simulation,"[{""name"": ""Qi Su"", ""position"": ""Product Director"", ""company"": ""Bytedance""}]",在本次演讲中，我们将深入探讨 SimReady 3D 资产的自动化构建方法研究与应用。SimReady 资产是 NVIDIA 率先提出的一种资产定义，具有准确的语义标签、物理属性和关节结构等真实信息，能够广泛应用于虚拟仿真、合成数据生成等生产工作流中，是数字孪生技术的核心组成部分。为实现这一目标，我们将从现有 3D 美术资产和 Gen3D 生成资产的语义标签、基于 AI 的物理属性推理以及关节结构生成三个方面展开讨论：首先，我们将使用 VLM 技术自动化识别 3D 美术资产的语义内容，并为其添加语义标签；其次，探讨如何推理出符合物理属性的 3D 美术资产，并进一步将其应用到 Gen3D 合成资产的属性自动生成上，最后将这些属性添加至 OpenUSD 文件中；最后，我们将讨论如何通过自动化手段将 3D 美术资产加工成具备关节结构的资产，以及如何直接合成带有关节结构的 Gen3D 资产。通过这些创新方法，我们旨在为 SimReady 3D 资产的构建提供一条自动化路径，推动 NVIDIA Omniverse 在更多场景中的广泛应用。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
应用于汽车行业聊天机器人的多模态检索增强生成方案,S72500,23:00,23:40,APAC,Simulive Room 2,,,,,Talks & Panels,Generative AI - Retrieval-Augmented Generation (RAG),"[{""name"": ""Guangfu Wang"", ""position"": ""Director"", ""company"": ""Great Wall Motor""}, {""name"": ""Alex Qiu"", ""position"": ""Sr. Solutions Architect"", ""company"": ""NVIDIA""}]",深入了解汽车行业开发检索增强生成 (RAG) 应用所面临的挑战和创新解决方案。我们提出了一种基于 LLM 的解决方案，用于处理不同的文档格式知识文档、增强多模态理解和改进语义检索，以显著提高特定领域聊天机器人和问答系统的准确性。了解我们的方法如何将 HTML 文档的问答准确率从 58%提高到 89%，并在更有挑战性的多模态 PDF 格式上实现了 91%的惊人成绩。了解如何利用这些优化方法构建针对汽车领域的更强大、更准确的 LLM 应用。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
构建面向微尺度建模和设计需求的大原子模型生态,S71873,20:30,21:10,APAC,Simulive Room 4,,,,,Talks & Panels,Simulation / Modeling / Design - Molecular Dynamics,"[{""name"": ""Linfeng Zhang"", ""position"": ""Co-Founder and Chief Scientist"", ""company"": ""DP Technology""}]",人工智能的快速发展正在推动分子建模、仿真和设计领域的重大变革。我们将探索 AI 辅助分子建模的突破和进展，重点关注从多尺度方法到大型预训练模型的转变，以及由此产生的软件、数据和模型生态系统。特别地，我们将强调 NVIDIA GPU带来的高性能计算能力的重要性，并探讨构建一个覆盖元素周期表的大原子模型 (LAM) 的可能性，并以此为基础，展望 LAM 赋能的行业未来。,Technical - Intermediate,Virtual,,,,,,,,,,,,,,
适用于商店和自动售货机的 AI 商业化,S71580,22:30,23:10,APAC,Simulive Room 4,,,,,Talks & Panels,Edge Computing - Autonomous Machines,"[{""name"": ""Yili Wu"", ""position"": ""CEO"", ""company"": ""SandStar""}]",对于零售商和 AI 公司而言，如何在数百万家商店和自动售货机中实现 AI 商业化始终是一项挑战。在过去 8 年中，SandStar 利用 AI 在 20 多个国家和地区至少降低了 70%的自动售货机成本，并将便利店收入增加了 10% 以上。了解如何借助 NVIDIA 技术支持实现这些业务优势。,Business / Executive,Virtual,,,,,,,,,,,,,,
